{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Gymnasium Mujoco Env\n",
    "参考：[test_mujoco_custom_env.py](https://github.com/Farama-Foundation/Gymnasium/blob/main/tests/envs/mujoco/test_mujoco_custom_env.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オリジナルのMuJoCo環境を作成します\n",
    "\n",
    "オリジナルのMuJoCo環境は，そのクラスを作ることで実装します．\n",
    "実査の学習を行うmain文的な処理は，gymのインターフェースであれば共通で使用できます．\n",
    "よって，自分なりの環境クラスを作成すればいいだけです．\n",
    "その環境クラスには，step, reset, render,などの必須なメソッドを定義する必要がありますが，MuJoCoでは使いやすくするためのサンプルがあります！\n",
    "よってそれを元に作るだけで，強化学習の環境が作れて，学習を回すことができます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__credits__ = [\"Kallinteris-Andreas\"]\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "\n",
    "class MouseEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Gymansium.MujocoEnv`環境APIを使った，マイクロマウスの強化学習環境\\n\n",
    "    まずは前進し続ける動作を行う環境を作成します．\\n\n",
    "    mujoco envを継承しています．\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"my_xmls/mouse_in_maze.xml\", frame_skip=1, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = self.data.qpos.size + self.data.qvel.size #たとえば，観測空間に位置と速度を入れたいのであれば，サイズを指定したいので，サイズを取る\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        x_position_before = self.data.qpos[0]\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "        x_position_after = self.data.qpos[0]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = x_position_after - x_position_before\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return observation, reward, False, False, info\n",
    "\n",
    "    def _get_obs(self): #状態空間を取得\n",
    "        position = self.data.qpos.flat.copy()\n",
    "        velocity = self.data.qvel.flat.copy()\n",
    "        return np.concatenate((position, velocity)) #npの値を連結して返す．これが状態空間となる\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "\n",
    "\n",
    "CHECK_ENV_IGNORE_WARNINGS = [\n",
    "    f\"\\x1b[33mWARN: {message}\\x1b[0m\"\n",
    "    for message in [\n",
    "        \"A Box observation space minimum value is -infinity. This is probably too low.\",\n",
    "        \"A Box observation space maximum value is infinity. This is probably too high.\",\n",
    "        \"For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"frame_skip\", [1, 2, 3, 4, 5])\n",
    "def test_frame_skip(frame_skip):\n",
    "    \"\"\"verify that custom envs work with different `frame_skip` values\"\"\"\n",
    "    env = MouseEnv(frame_skip=frame_skip)\n",
    "\n",
    "    # Test if env adheres to Gym API\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        check_env(env.unwrapped, skip_render_check=True)\n",
    "        env.close()\n",
    "    for warning in w:\n",
    "        if warning.message.args[0] not in CHECK_ENV_IGNORE_WARNINGS:\n",
    "            raise Error(f\"Unexpected warning: {warning.message}\")\n",
    "\n",
    "\n",
    "def test_xml_file():\n",
    "    \"\"\"Verify that the loading of a custom XML file works\"\"\"\n",
    "    relative_path = \"./tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=relative_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    full_path = os.getcwd() + \"/tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=full_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    # note can not test user home path (with '~') because github CI does not have a home folder\n",
    "\n",
    "\n",
    "def test_reset_info():\n",
    "    \"\"\"Verify that the environment returns info at `reset()`\"\"\"\n",
    "    env = MouseEnv()\n",
    "\n",
    "    _, info = env.reset()\n",
    "    assert info[\"works\"] is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デベロップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__credits__ = [\"Kallinteris-Andreas\"]\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "\n",
    "class MouseEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Gymansium.MujocoEnv`環境APIを使った，マイクロマウスの強化学習環境\\n\n",
    "    まずは前進し続ける動作を行う環境を作成します．\\n\n",
    "    mujoco envを継承しています．\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"my_xmls/mouse_in_maze_for_3_light.xml\", frame_skip=1, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = 14 #self.data.qpos.size + self.data.qvel.size #たとえば，観測空間に位置と速度を入れたいのであれば，サイズを指定したいので，サイズを取る\n",
    "        # self.wall_hit = 0\n",
    "        self.reward_graph = []\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        wall_hit = 0\n",
    "        velocity_before = self.data.sensor(\"Veloci\").data[0] # 前の速度を取る\n",
    "\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "        velocity_after = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        mouse_vel = velocity_after - velocity_before\n",
    "\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        center_sensor = ls - rs\n",
    "\n",
    "        hit_wall_f = self.data.sensor(\"HB1\").data[0] #フォースセンサの値取得\n",
    "        hit_wall_b = self.data.sensor(\"HB2\").data[0] #フォースセンサの値取得\n",
    "        truncated = False\n",
    "        # print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "        if hit_wall_f > 0 or hit_wall_b > 0:\n",
    "            # self.wall_hit = -10\n",
    "            wall_hit = -10\n",
    "            print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "            truncated = True\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = 10*(mouse_vel) + 0*(center_sensor) + wall_hit #self.wall_hitにしないほうが見通しが良い気がする\n",
    "        self.reward_graph.append(reward)\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return observation, reward, False, truncated, info\n",
    "\n",
    "    def _get_obs(self): #状態空間を取得\n",
    "        position = self.data.qpos.flat.copy()\n",
    "        velocity = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        lf = self.data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        rf = self.data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "        # 0次元配列（スカラー）を1次元配列に変換\n",
    "        velocity = np.array([velocity])\n",
    "        lf = np.array([lf])\n",
    "        ls = np.array([ls])\n",
    "        rs = np.array([rs])\n",
    "        rf = np.array([rf])\n",
    "\n",
    "        # # 結合\n",
    "        # observation = np.concatenate((position, velocity, lf, ls, rs, rf))\n",
    "\n",
    "        return np.concatenate((position, velocity, lf, ls, rs, rf)) #npの値を連結して返す．これが状態空間となる\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "    \n",
    "    # def _get_distance(model, data):\n",
    "    #     lf = data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "    #     ls = data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "    #     rs = data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "    #     rf = data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "    #     return lf,ls,rs,rf\n",
    "\n",
    "\n",
    "CHECK_ENV_IGNORE_WARNINGS = [\n",
    "    f\"\\x1b[33mWARN: {message}\\x1b[0m\"\n",
    "    for message in [\n",
    "        \"A Box observation space minimum value is -infinity. This is probably too low.\",\n",
    "        \"A Box observation space maximum value is infinity. This is probably too high.\",\n",
    "        \"For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"frame_skip\", [1, 2, 3, 4, 5])\n",
    "def test_frame_skip(frame_skip):\n",
    "    \"\"\"verify that custom envs work with different `frame_skip` values\"\"\"\n",
    "    env = MouseEnv(frame_skip=frame_skip)\n",
    "\n",
    "    # Test if env adheres to Gym API\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        check_env(env.unwrapped, skip_render_check=True)\n",
    "        env.close()\n",
    "    for warning in w:\n",
    "        if warning.message.args[0] not in CHECK_ENV_IGNORE_WARNINGS:\n",
    "            raise Error(f\"Unexpected warning: {warning.message}\")\n",
    "\n",
    "\n",
    "def test_xml_file():\n",
    "    \"\"\"Verify that the loading of a custom XML file works\"\"\"\n",
    "    relative_path = \"./tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=relative_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    full_path = os.getcwd() + \"/tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=full_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    # note can not test user home path (with '~') because github CI does not have a home folder\n",
    "\n",
    "\n",
    "def test_reset_info():\n",
    "    \"\"\"Verify that the environment returns info at `reset()`\"\"\"\n",
    "    env = MouseEnv()\n",
    "\n",
    "    _, info = env.reset()\n",
    "    assert info[\"works\"] is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "gym.envs.registration.register(id='MouseEnv-v0',entry_point=MouseEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gymのインターフェースになっているかチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:441: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = MouseEnv()\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cudaが使えるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:814: UserWarning: \u001b[33mWARN: The environment is being initialised with render_mode='none' that is not in the possible render_modes (['human', 'rgb_array']).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\rich\\live.py:231: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "The environment was initialized successfully however with an unsupported render mode. Render mode: none, modes: ['human', 'rgb_array']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m render_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# 1000ステップごとにレンダリング\u001b[39;00m\n\u001b[0;32m     45\u001b[0m callback \u001b[38;5;241m=\u001b[39m CustomCallback(render_freq)\n\u001b[1;32m---> 46\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# モデルのテスト\u001b[39;00m\n\u001b[0;32m     51\u001b[0m state, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()  \u001b[38;5;66;03m# ここを修正\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:200\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[0;32m    199\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:219\u001b[0m, in \u001b[0;36mCallbackList._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    216\u001b[0m continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# Return False (stop training) if at least one callback returns False\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m continue_training\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m continue_training\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m, in \u001b[0;36mCustomCallback._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_step\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# 一定の頻度でレンダリング\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 34\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:103\u001b[0m, in \u001b[0;36mDummyVecEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Gym environment rendering. If there are multiple environments then\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    they are tiled together in one image via ``BaseVecEnv.render()``.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    :param mode: The rendering type.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:273\u001b[0m, in \u001b[0;36mVecEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m bigimg\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# Other render modes:\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# In that case, we try to call `self.env.render()` but it might\u001b[39;00m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# crash for subprocesses\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# and we don't return the values\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:129\u001b[0m, in \u001b[0;36mDummyVecEnv.env_method\u001b[1;34m(self, method_name, indices, *method_args, **method_kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43menv_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_envs\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:129\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call instance methods of vectorized environments.\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m target_envs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_envs(indices)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmethod_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m env_i \u001b[38;5;129;01min\u001b[39;00m target_envs]\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:65\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_render_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:357\u001b[0m, in \u001b[0;36menv_render_passive_checker\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    354\u001b[0m             env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith no render_modes, expects the Env.render_mode to be None, actual value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 357\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01min\u001b[39;00m render_modes, (\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment was initialized successfully however with an unsupported render mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, modes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_modes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    362\u001b[0m result \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: The environment was initialized successfully however with an unsupported render mode. Render mode: none, modes: ['human', 'rgb_array']"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC, PPO\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# env = gym.make(\"ALE/Breakout-v5\",  render_mode=\"human\")\n",
    "# env = gym.make(\"CartPole-v1\",  render_mode=\"human\")\n",
    "# # env = Monitor(env, \"./gym-results\", force=True, video_callable=lambda episode: True)　こんな感じで，\n",
    "# model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=200)\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class ProgressCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(ProgressCallback, self).__init__(verbose)\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # エピソードが終了したかどうかをチェック\n",
    "        if 'episode' in self.locals:\n",
    "            self.episode_count += 1\n",
    "            print(f\"ああああEpisode: {self.episode_count}, Reward: {self.locals['episode']['r']}\")\n",
    "        return True\n",
    "    \n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, render_freq):\n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.render_freq = render_freq\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # 一定の頻度でレンダリング\n",
    "        if self.num_timesteps % self.render_freq == 0:\n",
    "            self.training_env.render()\n",
    "        return True\n",
    "\n",
    "# # 使用例\n",
    "# model.learn(total_timesteps=5000, callback=ProgressCallback())\n",
    "\n",
    "env = gym.make(\"CartPole-v1\",  render_mode=\"none\")\n",
    "# env.model.opt.timestep = 0.01  # タイムステップを設定\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "# model = PPO.load('test',env)\n",
    "render_freq = 1000  # 1000ステップごとにレンダリング\n",
    "callback = CustomCallback(render_freq)\n",
    "model.learn(total_timesteps=10000,progress_bar = True, callback=callback)\n",
    "\n",
    "\n",
    "\n",
    "# モデルのテスト\n",
    "state, _ = env.reset()  # ここを修正\n",
    "for i in trange(600):\n",
    "    # 環境の描画\n",
    "    env.render()\n",
    "\n",
    "    # モデルの推論\n",
    "    action, _ = model.predict(state)\n",
    "\n",
    "    # 1ステップ実行\n",
    "    obs, reward, terminated, truncated, info = env.step(action) #以前の4要素のタプルから5要素のタプルに変更され，`observation, reward, terminated, truncated, info`という形式になった。\n",
    "\n",
    "\n",
    "\n",
    "    # エピソード完了（終了または切り捨て）のチェック terminated(終了した)は目的を達成してエピソードを終了したことを表す，truncated(切り捨てられた)は，達成できずにエピソードが終了したことを表す\n",
    "    if terminated or truncated:\n",
    "        state, _ = env.reset() # エピソードが終了したら、環境をリセット\n",
    "# モデルの保存 (1)\n",
    "model.save('test')\n",
    "plt.title(\"1マス前進\", fontname=\"MS Gothic\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"step(s)\", fontname=\"MS Gothic\")\n",
    "plt.ylabel(\"速度[m/s]\", fontname=\"MS Gothic\")\n",
    "\n",
    "#前進関係のプロット\n",
    "t = list(range(len(env.reward_graph)))  # 0から始まるインデックスのリストを作成\n",
    "# plt.plot(t, env.reward_graph, linestyle='solid', label=\"報酬\")\n",
    "plt.legend()\n",
    "# 環境のクローズ\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('CartPole-v1')\n",
    "print(env.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env.step(action)の戻り値の更新について（４つから５つになりました）\n",
    "Gymライブラリのバージョン0.26以降、及びGymnasiumの全バージョンにおいて、`env.step()`メソッドの戻り値は、以前の4要素のタプルから5要素のタプルに変更されました。これまでの`observation, reward, done, info`という形式から、`observation, reward, terminated, truncated, info`という形式になっています。\n",
    "\n",
    "ここでの`terminated`と`truncated`はどちらもブール値（真偽値）です。`terminated`は環境がマルコフ決定過程（MDP）のタスクの定義に基づいて終了状態に達したことを示します。これは通常、環境の目標が達成されたり、終了条件が満たされたときに発生します。一方、`truncated`は、エピソードがMDPの範囲外の条件、たとえば時間制限や境界条件（エージェントが境界を越えるなど）によって終了したことを示します。強化学習アルゴリズムにおいて、特にブートストラップを伴うものでは、終了と切り捨て状態の取り扱いが値の更新において異なる場合があるため、この区別は重要です。\n",
    "\n",
    "Gymライブラリのこの更新は、強化学習タスクにおける終了と切り捨ての明確な区別を提供するために行われました。これは、特定のアルゴリズムの正確な実装にとって重要です。終了(`terminated`)と切り捨て(`truncated`)の両方のタイプのエピソード終了を区別するために、両方が含まれるようになりました。\n",
    "\n",
    "あなたの目的に合わせて、エピソードが終了したかどうか（理由に関係なく）を知りたい場合は、`terminated`または`truncated`のいずれかが`True`であるかどうかを確認すればよいです。その場合、環境をリセットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのテスト\n",
    "state, _ = env.reset()  # ここを修正\n",
    "for i in trange(4000):\n",
    "    # 環境の描画\n",
    "    env.render()\n",
    "\n",
    "    # モデルの推論\n",
    "    action, _ = model.predict(state)\n",
    "\n",
    "    # 1ステップ実行\n",
    "    state, rewards, done, info = env.step(action)\n",
    "\n",
    "    # エピソード完了\n",
    "    if done:\n",
    "        state, _ = env.reset()  # エピソードが終了したら、環境をリセット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_string_example():\n",
    "        \"\"\"ドックストリング（Docstring）\n",
    "        この関数は以下のことを行います：\\n\n",
    "    - param1を処理します。\\n\n",
    "    - param2を別の方法で処理します。\\n\n",
    "    最後に、結果を返します。\n",
    "        シミュレーションをnフレーム進め、制御アクションを適用する。\n",
    "        Step the simulation n number of frames and applying a control action.\n",
    "        \"\"\"\n",
    "        p = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
