{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Gymnasium Mujoco Env\n",
    "参考：[test_mujoco_custom_env.py](https://github.com/Farama-Foundation/Gymnasium/blob/main/tests/envs/mujoco/test_mujoco_custom_env.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オリジナルのMuJoCo環境を作成します\n",
    "\n",
    "オリジナルのMuJoCo環境は，そのクラスを作ることで実装します．\n",
    "実査の学習を行うmain文的な処理は，gymのインターフェースであれば共通で使用できます．\n",
    "よって，自分なりの環境クラスを作成すればいいだけです．\n",
    "その環境クラスには，step, reset, render,などの必須なメソッドを定義する必要がありますが，MuJoCoでは使いやすくするためのサンプルがあります！\n",
    "よってそれを元に作るだけで，強化学習の環境が作れて，学習を回すことができます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__credits__ = [\"Kallinteris-Andreas\"]\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "\n",
    "class MouseEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Gymansium.MujocoEnv`環境APIを使った，マイクロマウスの強化学習環境\\n\n",
    "    まずは前進し続ける動作を行う環境を作成します．\\n\n",
    "    mujoco envを継承しています．\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"my_xmls/mouse_in_maze.xml\", frame_skip=1, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = self.data.qpos.size + self.data.qvel.size #たとえば，観測空間に位置と速度を入れたいのであれば，サイズを指定したいので，サイズを取る\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        x_position_before = self.data.qpos[0]\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "        x_position_after = self.data.qpos[0]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = x_position_after - x_position_before\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return observation, reward, False, False, info\n",
    "\n",
    "    def _get_obs(self): #状態空間を取得\n",
    "        position = self.data.qpos.flat.copy()\n",
    "        velocity = self.data.qvel.flat.copy()\n",
    "        return np.concatenate((position, velocity)) #npの値を連結して返す．これが状態空間となる\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "\n",
    "\n",
    "CHECK_ENV_IGNORE_WARNINGS = [\n",
    "    f\"\\x1b[33mWARN: {message}\\x1b[0m\"\n",
    "    for message in [\n",
    "        \"A Box observation space minimum value is -infinity. This is probably too low.\",\n",
    "        \"A Box observation space maximum value is infinity. This is probably too high.\",\n",
    "        \"For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"frame_skip\", [1, 2, 3, 4, 5])\n",
    "def test_frame_skip(frame_skip):\n",
    "    \"\"\"verify that custom envs work with different `frame_skip` values\"\"\"\n",
    "    env = MouseEnv(frame_skip=frame_skip)\n",
    "\n",
    "    # Test if env adheres to Gym API\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        check_env(env.unwrapped, skip_render_check=True)\n",
    "        env.close()\n",
    "    for warning in w:\n",
    "        if warning.message.args[0] not in CHECK_ENV_IGNORE_WARNINGS:\n",
    "            raise Error(f\"Unexpected warning: {warning.message}\")\n",
    "\n",
    "\n",
    "def test_xml_file():\n",
    "    \"\"\"Verify that the loading of a custom XML file works\"\"\"\n",
    "    relative_path = \"./tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=relative_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    full_path = os.getcwd() + \"/tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=full_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    # note can not test user home path (with '~') because github CI does not have a home folder\n",
    "\n",
    "\n",
    "def test_reset_info():\n",
    "    \"\"\"Verify that the environment returns info at `reset()`\"\"\"\n",
    "    env = MouseEnv()\n",
    "\n",
    "    _, info = env.reset()\n",
    "    assert info[\"works\"] is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デベロップ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オドメトリなしの小さめ構成の環境　視認性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__credits__ = [\"Kallinteris-Andreas\"]\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "\n",
    "class MouseEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Gymansium.MujocoEnv`環境APIを使った，マイクロマウスの強化学習環境\\n\n",
    "    まずは前進し続ける動作を行う環境を作成します．\\n\n",
    "    mujoco envを継承しています．\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"my_xmls/mouse_in_maze_for_3_light.xml\", frame_skip=50, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = 14 #self.data.qpos.size + self.data.qvel.size #たとえば，観測空間に位置と速度を入れたいのであれば，サイズを指定したいので，サイズを取る\n",
    "        # self.wall_hit = 0\n",
    "        self.reward_graph = []\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        wall_hit = 0\n",
    "        velocity_before = self.data.sensor(\"Veloci\").data[0] # 前の速度を取る\n",
    "\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "        velocity_after = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        mouse_vel = velocity_after - velocity_before\n",
    "\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        center_sensor = ls - rs\n",
    "\n",
    "        hit_wall_f = self.data.sensor(\"HB1\").data[0] #フォースセンサの値取得\n",
    "        hit_wall_b = self.data.sensor(\"HB2\").data[0] #フォースセンサの値取得\n",
    "        truncated = False\n",
    "        # print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "        if hit_wall_f > 0 or hit_wall_b > 0:\n",
    "            # self.wall_hit = -10\n",
    "            wall_hit = -10\n",
    "            print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "            truncated = True\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = 10*(mouse_vel) + 0*(center_sensor) + wall_hit #self.wall_hitにしないほうが見通しが良い気がする\n",
    "        self.reward_graph.append(reward)\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return observation, reward, False, truncated, info\n",
    "\n",
    "    def _get_obs(self): #状態空間を取得\n",
    "        position = self.data.qpos.flat.copy()\n",
    "        velocity = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        lf = self.data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        rf = self.data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "        # 0次元配列（スカラー）を1次元配列に変換\n",
    "        velocity = np.array([velocity])\n",
    "        lf = np.array([lf])\n",
    "        ls = np.array([ls])\n",
    "        rs = np.array([rs])\n",
    "        rf = np.array([rf])\n",
    "\n",
    "        # # 結合\n",
    "        # observation = np.concatenate((position, velocity, lf, ls, rs, rf))\n",
    "\n",
    "        return np.concatenate((position, velocity, lf, ls, rs, rf)) #npの値を連結して返す．これが状態空間となる\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "    \n",
    "    # def _get_distance(model, data):\n",
    "    #     lf = data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "    #     ls = data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "    #     rs = data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "    #     rf = data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "    #     return lf,ls,rs,rf\n",
    "\n",
    "\n",
    "CHECK_ENV_IGNORE_WARNINGS = [\n",
    "    f\"\\x1b[33mWARN: {message}\\x1b[0m\"\n",
    "    for message in [\n",
    "        \"A Box observation space minimum value is -infinity. This is probably too low.\",\n",
    "        \"A Box observation space maximum value is infinity. This is probably too high.\",\n",
    "        \"For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"frame_skip\", [1, 2, 3, 4, 5])\n",
    "def test_frame_skip(frame_skip):\n",
    "    \"\"\"verify that custom envs work with different `frame_skip` values\"\"\"\n",
    "    env = MouseEnv(frame_skip=frame_skip)\n",
    "\n",
    "    # Test if env adheres to Gym API\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        check_env(env.unwrapped, skip_render_check=True)\n",
    "        env.close()\n",
    "    for warning in w:\n",
    "        if warning.message.args[0] not in CHECK_ENV_IGNORE_WARNINGS:\n",
    "            raise Error(f\"Unexpected warning: {warning.message}\")\n",
    "\n",
    "\n",
    "def test_xml_file():\n",
    "    \"\"\"Verify that the loading of a custom XML file works\"\"\"\n",
    "    relative_path = \"./tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=relative_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    full_path = os.getcwd() + \"/tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=full_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    # note can not test user home path (with '~') because github CI does not have a home folder\n",
    "\n",
    "\n",
    "def test_reset_info():\n",
    "    \"\"\"Verify that the environment returns info at `reset()`\"\"\"\n",
    "    env = MouseEnv()\n",
    "\n",
    "    _, info = env.reset()\n",
    "    assert info[\"works\"] is True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態にオドメトリによる座標を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__credits__ = [\"Kallinteris-Andreas\"]\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pytest\n",
    "import random\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "\n",
    "class MouseEnv(MujocoEnv, utils.EzPickle):\n",
    "    \"\"\"\n",
    "    Gymansium.MujocoEnv`環境APIを使った，マイクロマウスの強化学習環境\\n\n",
    "    まずは前進し続ける動作を行う環境を作成します．\\n\n",
    "    mujoco envを継承しています．\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"my_xmls/assemble_mouse_mas_rand_training.xml\", frame_skip=10, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = 8 #self.data.qpos.size + self.data.qvel.size #たとえば，観測空間に位置と速度を入れたいのであれば，サイズを指定したいので，サイズを取る\n",
    "        # self.wall_hit = 0\n",
    "        #マイクロマウスのパラメータ用変数\n",
    "        self.reward_graph = []\n",
    "        self.mouse_xpos_graph = []\n",
    "        self.mouse_ypos_graph = []\n",
    "        self.mouse_angle_rad = math.pi/2\n",
    "        self.mouse_xpos = 0\n",
    "        self.mouse_ypos = 0\n",
    "        self.mouse_vel = 0\n",
    "        self.now_time = 0\n",
    "        self.past_time = 0\n",
    "        self.delta_t = 0\n",
    "        self.wheel_r = 0\n",
    "        self.gear = 9.0e-3\n",
    "        self.wheel_r = 0.0135\n",
    "        self.tread = 0.072\n",
    "        self.right_rotation_sum = 0\n",
    "        self.left_rotation_sum = 0\n",
    "        \n",
    "\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def get_odom(self, model, data): #今のタイヤの回転角度と速度（角度と角速度）を求める．\n",
    "        odm_right = data.actuator('right').length[0]/self.gear # 得た値をgearで割ったもの＝タイヤの角度(rad)\n",
    "        odm_left = data.actuator('left').length[0]/self.gear # ＝タイヤの角度\n",
    "        vel_left = data.actuator('left').velocity[0]/self.gear # ＝タイヤの回転角速度\n",
    "        return odm_right, odm_left\n",
    "    \n",
    "    def get_pulse_count(self, pre_odm_right, pre_odm_left, odm_right, odm_left): #回転量をパルスにする エンコーダの役割をする関数\n",
    "        \"\"\"\n",
    "            回転量の差から，パルス数を求める． エンコーダの役割をする関数\\\\\n",
    "            Returns:\n",
    "                right_pulse_num = 右タイヤのパルス数 \\\\\n",
    "                left_pulse_num = 左タイヤのパルス数\n",
    "            \"\"\"\n",
    "        \n",
    "        pre_right_rotation_sum = self.right_rotation_sum\n",
    "        pre_left_rotation_sum = self.left_rotation_sum\n",
    "        self.right_rotation_sum += (odm_right - pre_odm_right)/(2*math.pi) *4096 #1周あたり4096段階で，細かい回転量を計測（分解能ほぼ無限のエンコーダ）\n",
    "        self.left_rotation_sum += (odm_left - pre_odm_left)/(2*math.pi) *4096 #1周あたり4096段階で，細かい回転量を計測（分解能ほぼ無限のエンコーダ）\n",
    "        right_pulse_num = int(self.right_rotation_sum) - int(pre_right_rotation_sum)\n",
    "        left_pulse_num = int(self.left_rotation_sum) - int(pre_left_rotation_sum)\n",
    "        # print(\"回転量をパルス段階に変換　この値の差が，実際に出たパルスとなる：\", right_pulse_num)\n",
    "        return right_pulse_num, left_pulse_num\n",
    "    \n",
    "    def get_odom_at_pulse(self, right_pulse_num, left_pulse_num): #今のタイヤの回転角度と速度（角度と角速度）を求める．\n",
    "        right_wheel_move = 2*math.pi * self.wheel_r * (right_pulse_num/4096) #２πｒ×回転数で移動距離を求める．/delta_t\n",
    "        left_wheel_move = 2*math.pi * self.wheel_r * (left_pulse_num/4096) #２πｒ×回転数で移動距離を求める．\n",
    "        right_wheel_vel = right_wheel_move/self.delta_t #移動距離から，速度を求める\n",
    "        left_wheel_vel = left_wheel_move/self.delta_t #移動距離から，速度を求める\n",
    "        mouse_vel = (right_wheel_vel + left_wheel_vel)/2 #左右平均が並進速度\n",
    "        mouse_radvel = (right_wheel_vel - left_wheel_vel)/self.tread #これがマウスの旋回角速度（rad/s）\n",
    "        return mouse_vel, mouse_radvel #これで，エンコーダによる各タイヤの推定速度が求められた\n",
    "\n",
    "    def step(self, action):\n",
    "        wall_hit = 0\n",
    "        course_out = 0\n",
    "        goal = 0\n",
    "        velocity_before = self.data.sensor(\"Veloci\").data[0] # 前の速度を取る\n",
    "        # ####オドメトリ####\n",
    "        self.past_time = self.data.time\n",
    "        # エンコーダを読み取る\n",
    "        pre_odm_right, pre_odm_left = self.get_odom(self.model, self.data)\n",
    "\n",
    "        self.do_simulation(action, self.frame_skip)####################シミュレーション実行##############################\n",
    "        self.now_time = self.data.time\n",
    "        self.delta_t = self.now_time - self.past_time #シミュレーションが1ステップ終わった後の時間を取得\n",
    "        self.past_time = self.now_time\n",
    "        # エンコーダをもう一度読み取る　（行動後の値を取得）\n",
    "        odm_right, odm_left = self.get_odom(self.model, self.data)\n",
    "        # エンコーダ値から，この一瞬に出たパルス数を算出し，\n",
    "        right_pulse_num, left_pulse_num = self.get_pulse_count(pre_odm_right, pre_odm_left, odm_right, odm_left)\n",
    "        # パルス数から，移動速度と角速度を求める\n",
    "        mouse_vel, mouse_rad_vel = self.get_odom_at_pulse(right_pulse_num, left_pulse_num) #これで，エンコーダによるマウスの速度・角速度が推定できた\n",
    "        # 速度に時間を掛けて，移動距離を計算 まず向きを計算し，その後移動距離を求める\n",
    "        self.mouse_angle_rad += mouse_rad_vel * self.delta_t #マウスの角速度はパルスの左右差で求められるので，現在の角度は\n",
    "        # print(\"関数内は：\", mouse_angle_rad)\n",
    "        self.mouse_xpos += mouse_vel * math.cos(self.mouse_angle_rad) * self.delta_t #オドメトリで座標推定\n",
    "        self.mouse_ypos += mouse_vel * math.sin(self.mouse_angle_rad) * self.delta_t\n",
    "        self.mouse_xpos_graph.append(self.mouse_xpos)\n",
    "        self.mouse_ypos_graph.append(self.mouse_ypos)\n",
    "        ####オドメトリ####\n",
    "\n",
    "        # velocity_after = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        # mouse_vel = velocity_after - velocity_before\n",
    "        # if mouse_vel < 0:\n",
    "        #     3*mouse_vel\n",
    "        self.mouse_vel = mouse_vel\n",
    "        \n",
    "\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        center_sensor = ls - rs\n",
    "\n",
    "        hit_wall_f = self.data.sensor(\"HB1\").data[0] #フォースセンサの値取得\n",
    "        hit_wall_b = self.data.sensor(\"HB2\").data[0] #フォースセンサの値取得\n",
    "        truncated = False\n",
    "        # print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "        if hit_wall_f > 0 or hit_wall_b > 0:\n",
    "            # print(\"hit\")\n",
    "            # self.wall_hit = -10\n",
    "            wall_hit = -1\n",
    "            # print(\"hit wall\", hit_wall_f, hit_wall_b)\n",
    "            truncated = True\n",
    "\n",
    "        mouse_Zpos = self.data.qpos[2] \n",
    "        if mouse_Zpos < -0.1:\n",
    "            course_out = -1\n",
    "            # print(\"course_out\")\n",
    "            truncated = True\n",
    "        goal_1 = self.data.sensor('goal_1').data[0]\n",
    "        goal_2 = self.data.sensor('goal_2').data[0]\n",
    "        goal_3 = self.data.sensor('goal_3').data[0]\n",
    "        goal_4 = self.data.sensor('goal_4').data[0]\n",
    "        goal_5 = self.data.sensor('goal_5').data[0]\n",
    "        goal_6 = self.data.sensor('goal_6').data[0]\n",
    "        goal_7 = self.data.sensor('goal_7').data[0]\n",
    "        goal_8 = self.data.sensor('goal_8').data[0]\n",
    "        if goal_1 > 0 or goal_2 > 0 or goal_3 > 0 or goal_4 > 0 or goal_5 > 0 or goal_6 > 0 or goal_7 > 0 or goal_8 > 0:\n",
    "            goal = 1\n",
    "            wall_hit = 0\n",
    "            # print(\"goal\")\n",
    "            truncated = True\n",
    "\n",
    "        \n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = 1*(mouse_vel) + 0*(center_sensor) + wall_hit + course_out + goal -0.0001 #self.wall_hitにしないほうが見通しが良い気がする\n",
    "        self.reward_graph.append(reward)\n",
    "        info = {}\n",
    "        \n",
    "        \n",
    "            \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return observation, reward, False, truncated, info\n",
    "\n",
    "    def _get_obs(self): #状態空間を取得\n",
    "        # position = self.data.qpos.flat.copy()\n",
    "        # velocity = self.data.sensor(\"Veloci\").data[0] # 今の速度を取る\n",
    "        lf = self.data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "        ls = self.data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "        rs = self.data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "        rf = self.data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "        # gyro = self.data.sensor('Gyro').data[0]#sensordata[rf_id]\n",
    "        mouse_angle_rad = np.array([self.mouse_angle_rad])\n",
    "        mouse_xpos = np.array([self.mouse_xpos])\n",
    "        mouse_ypos = np.array([self.mouse_ypos])\n",
    "        mouse_vel = np.array([self.mouse_vel])\n",
    "        mouse_angle_rad = np.array([self.mouse_angle_rad])\n",
    "        # 0次元配列（スカラー）を1次元配列に変換\n",
    "        # gyro = np.array([gyro])\n",
    "        # velocity = np.array([velocity])\n",
    "        lf = np.array([lf])\n",
    "        ls = np.array([ls])\n",
    "        rs = np.array([rs])\n",
    "        rf = np.array([rf])\n",
    "\n",
    "        # # 結合\n",
    "        # observation = np.concatenate((position, velocity, lf, ls, rs, rf))\n",
    "\n",
    "        # return np.concatenate((position, velocity, lf, ls, rs, rf, gyro)) #mouse_angle_rad, mouse_xpos, mouse_ypos, gyro)) #npの値を連結して返す．これが状態空間となる\n",
    "        return np.concatenate((mouse_xpos, mouse_ypos, mouse_vel, lf, ls, rs, rf, mouse_angle_rad)) #mouse_angle_rad, mouse_xpos, mouse_ypos, gyro)) #npの値を連結して返す．これが状態空間となる\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "\n",
    "        x_values = [0.27, 1.07, 1.87]\n",
    "        mouse_xposition_shuffle = random.choice(x_values)\n",
    "\n",
    "        # mouse_xposition_shuffle = self.course_list[np.random]\n",
    "        # mouse_yposition_shuffle = self.course_list[np.random]\n",
    "\n",
    "        #両方3のときはやり直しする処理\n",
    "        \n",
    "        qpos[0] = mouse_xposition_shuffle\n",
    "        # noise = np.random.normal(0, 0.3)  # 平均0、標準偏差0.1のノイズ\n",
    "        # self.data.qpos[3] += np.random.normal(0, 0.3)#0.27 1.07\n",
    "        # qpos[1] = mouse_yposition_shuffle\n",
    "        self.set_state(qpos, qvel) #qposとqvelには，すべての位置と速度の値がならんでいるためそれをセットする\n",
    "        self.mouse_angle_rad = 0\n",
    "        self.mouse_xpos = 0\n",
    "        # self.mouse_ypos = 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "    \n",
    "    # def _get_distance(model, data):\n",
    "    #     lf = data.sensor('LF').data[0]#sensordata[lf_id]\n",
    "    #     ls = data.sensor('LS').data[0]#sensordata[ls_id]\n",
    "    #     rs = data.sensor('RS').data[0]#sensordata[rs_id]\n",
    "    #     rf = data.sensor('RF').data[0]#sensordata[rf_id]\n",
    "    #     return lf,ls,rs,rf\n",
    "\n",
    "\n",
    "CHECK_ENV_IGNORE_WARNINGS = [\n",
    "    f\"\\x1b[33mWARN: {message}\\x1b[0m\"\n",
    "    for message in [\n",
    "        \"A Box observation space minimum value is -infinity. This is probably too low.\",\n",
    "        \"A Box observation space maximum value is infinity. This is probably too high.\",\n",
    "        \"For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"frame_skip\", [1, 2, 3, 4, 5])\n",
    "def test_frame_skip(frame_skip):\n",
    "    \"\"\"verify that custom envs work with different `frame_skip` values\"\"\"\n",
    "    env = MouseEnv(frame_skip=frame_skip)\n",
    "\n",
    "    # Test if env adheres to Gym API\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        check_env(env.unwrapped, skip_render_check=True)\n",
    "        env.close()\n",
    "    for warning in w:\n",
    "        if warning.message.args[0] not in CHECK_ENV_IGNORE_WARNINGS:\n",
    "            raise Error(f\"Unexpected warning: {warning.message}\")\n",
    "\n",
    "\n",
    "def test_xml_file():\n",
    "    \"\"\"Verify that the loading of a custom XML file works\"\"\"\n",
    "    relative_path = \"./tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=relative_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    full_path = os.getcwd() + \"/tests/envs/mujoco/assets/walker2d_v5_uneven_feet.xml\"\n",
    "    env = MouseEnv(xml_file=full_path).unwrapped\n",
    "    assert isinstance(env, MujocoEnv)\n",
    "    assert env.data.qpos.size == 9\n",
    "\n",
    "    # note can not test user home path (with '~') because github CI does not have a home folder\n",
    "\n",
    "\n",
    "def test_reset_info():\n",
    "    \"\"\"Verify that the environment returns info at `reset()`\"\"\"\n",
    "    env = MouseEnv()\n",
    "\n",
    "    _, info = env.reset()\n",
    "    assert info[\"works\"] is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mujoco\n",
    "# import time\n",
    "# import mujoco.viewer\n",
    "# #Create model\n",
    "# model = mujoco.MjModel.from_xml_path('./xmls_backup_in_gymenv_my_xmls/assemble_mouse_mas_rand_training.xml')\n",
    "# data = mujoco.MjData(model)\n",
    "# print(data.qpos)\n",
    "# data.qpos[0] = 1.87#0.27 1.07\n",
    "# noise = np.random.normal(0, 0.3)  # 平均0、標準偏差0.1のノイズ\n",
    "# data.qpos[3] += noise#0.27 1.07\n",
    "# print(data.qpos)\n",
    "# # print(data.body(\"torso\").xpos)\n",
    "# with mujoco.viewer.launch_passive(model, data, ) as viewer: #モデルをプログラムから確認\n",
    "#   time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 環境登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "gym.envs.registration.register(id='MouseEnv-v0',max_episode_steps=600,entry_point=MouseEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gymのインターフェースになっているかチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\env_checker.py:441: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = MouseEnv()\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cudaが使えるか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINE BOTに接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINE BOT  ON\n",
    "\n",
    "import requests\n",
    "\n",
    "class LINENotifyBot(object):\n",
    "    API_URL = 'https://notify-api.line.me/api/notify'\n",
    "    def __init__(self, access_token):\n",
    "        self.__headers = {'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "    def send(\n",
    "        self,\n",
    "        message,\n",
    "        image=None,\n",
    "        sticker_package_id=None,\n",
    "        sticker_id=None,\n",
    "    ):\n",
    "        payload = {\n",
    "            'message': message,\n",
    "            'stickerPackageId': sticker_package_id,\n",
    "            'stickerId': sticker_id,\n",
    "        }\n",
    "        files = {}\n",
    "        if image != None:\n",
    "            files = {'imageFile': open(image, 'rb')}\n",
    "        r = requests.post(\n",
    "            LINENotifyBot.API_URL,\n",
    "            headers=self.__headers,\n",
    "            data=payload,\n",
    "            files=files,\n",
    "        )\n",
    "\n",
    "\n",
    "bot = LINENotifyBot(access_token='UuzEJNM69oW7g0suO2FsWygFKvSK4vj7HnEBFLyi0mc')\n",
    "bot.send(\n",
    "message=\"LINE BOTを起動します。 \\n 大量の通知が行きます\",\n",
    "#image='picf' + str(i) + '.png',  # png or jpg\n",
    "sticker_package_id=1,\n",
    "sticker_id=6,\n",
    ")\n",
    "# print(\"LINE BOTを起動します。 \\n 大量の通知が行きます\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.model to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.model` for environment variables or `env.get_wrapper_attr('model')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.3     |\n",
      "|    ep_rew_mean     | -0.971   |\n",
      "| time/              |          |\n",
      "|    fps             | 148      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.1        |\n",
      "|    ep_rew_mean          | -0.643      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017213084 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15.6        |\n",
      "|    ep_rew_mean          | 0.0951      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012529295 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | 0.0837      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.5        |\n",
      "|    ep_rew_mean          | 0.0895      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004490533 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.77       |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    std                  | 0.964       |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 12.5         |\n",
      "|    ep_rew_mean          | 0.264        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046422547 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.273        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.954        |\n",
      "|    value_loss           | 0.463        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.9        |\n",
      "|    ep_rew_mean          | 0.273       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474007 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.75       |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    std                  | 0.957       |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 11.4         |\n",
      "|    ep_rew_mean          | 0.331        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038830275 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.76        |\n",
      "|    explained_variance   | 0.0947       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.292        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.638        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.2        |\n",
      "|    ep_rew_mean          | 0.288       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009901995 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.334       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.954       |\n",
      "|    value_loss           | 0.537       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.4        |\n",
      "|    ep_rew_mean          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010935794 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 0.719       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 0.588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007975622 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.457       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.824       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.5     |\n",
      "|    ep_rew_mean     | 0.75     |\n",
      "| time/              |          |\n",
      "|    fps             | 415      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 11.3         |\n",
      "|    ep_rew_mean          | 0.782        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 390          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060445047 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.65        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.495        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00742     |\n",
      "|    std                  | 0.905        |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 0.979       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 386         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008997422 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.485       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.9        |\n",
      "|    ep_rew_mean          | 0.942       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009333145 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.6        |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.516       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.2        |\n",
      "|    ep_rew_mean          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005484346 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.514       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.9        |\n",
      "|    ep_rew_mean          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010422493 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.534       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 11.2         |\n",
      "|    ep_rew_mean          | 1.35         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 382          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071313046 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.311        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.745        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    std                  | 0.838        |\n",
      "|    value_loss           | 1.3          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.4        |\n",
      "|    ep_rew_mean          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 381         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010363853 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.546       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.5        |\n",
      "|    ep_rew_mean          | 1.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009606851 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.745       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.809       |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.5       |\n",
      "|    ep_rew_mean          | 1.34       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 381        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00716307 |\n",
      "|    clip_fraction        | 0.0679     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.39      |\n",
      "|    explained_variance   | 0.485      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.746      |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00585   |\n",
      "|    std                  | 0.794      |\n",
      "|    value_loss           | 1.38       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.3     |\n",
      "|    ep_rew_mean     | 1.58     |\n",
      "| time/              |          |\n",
      "|    fps             | 423      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027997 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.763       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    std                  | 0.774       |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.8        |\n",
      "|    ep_rew_mean          | 1.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009914653 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.962       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 12.8         |\n",
      "|    ep_rew_mean          | 1.77         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 383          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055417586 |\n",
      "|    clip_fraction        | 0.0704       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.76         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 0.741        |\n",
      "|    value_loss           | 1.48         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 0.981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011906771 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.662       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    std                  | 0.732       |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 15          |\n",
      "|    ep_rew_mean          | 1.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010516936 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.586       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    std                  | 0.717       |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.4        |\n",
      "|    ep_rew_mean          | 1.52        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009064784 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.731       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.701       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.8        |\n",
      "|    ep_rew_mean          | 1.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008135782 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.671       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 1.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.7        |\n",
      "|    ep_rew_mean          | 1.68        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008257529 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.683       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.67        |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.2        |\n",
      "|    ep_rew_mean          | 1.59        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010313071 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.611       |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.659       |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.1     |\n",
      "|    ep_rew_mean     | 1.95     |\n",
      "| time/              |          |\n",
      "|    fps             | 173      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.7         |\n",
      "|    ep_rew_mean          | 1.69         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 234          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076004174 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.46         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00874     |\n",
      "|    std                  | 0.63         |\n",
      "|    value_loss           | 1.38         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.9        |\n",
      "|    ep_rew_mean          | 1.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009617145 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.432       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    std                  | 0.616       |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 13           |\n",
      "|    ep_rew_mean          | 2.02         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057321857 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.833        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    std                  | 0.607        |\n",
      "|    value_loss           | 1.69         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.5        |\n",
      "|    ep_rew_mean          | 1.78        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007950434 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.595       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    std                  | 0.599       |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 11           |\n",
      "|    ep_rew_mean          | 1.77         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 313          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090325065 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.489        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00855     |\n",
      "|    std                  | 0.594        |\n",
      "|    value_loss           | 1.45         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.57        |\n",
      "|    ep_rew_mean          | 1.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007347308 |\n",
      "|    clip_fraction        | 0.0787      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.598       |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    std                  | 0.588       |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.65        |\n",
      "|    ep_rew_mean          | 1.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 329         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014041339 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    std                  | 0.588       |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10.4       |\n",
      "|    ep_rew_mean          | 2.07       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 334        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01026935 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    std                  | 0.588      |\n",
      "|    value_loss           | 1.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.96        |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 339         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009320053 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.861       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.588       |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.88     |\n",
      "|    ep_rew_mean     | 1.8      |\n",
      "| time/              |          |\n",
      "|    fps             | 448      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.95       |\n",
      "|    ep_rew_mean          | 1.83       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 414        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01177305 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.08       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00947   |\n",
      "|    std                  | 0.589      |\n",
      "|    value_loss           | 1.82       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10.7         |\n",
      "|    ep_rew_mean          | 2            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064827413 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.851        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.723        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    std                  | 0.583        |\n",
      "|    value_loss           | 1.4          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.2        |\n",
      "|    ep_rew_mean          | 1.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007267096 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.466       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    std                  | 0.576       |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.2        |\n",
      "|    ep_rew_mean          | 1.74        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012438554 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.465       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.89        |\n",
      "|    ep_rew_mean          | 2.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007257482 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    std                  | 0.568       |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.3        |\n",
      "|    ep_rew_mean          | 1.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010961747 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.816       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.562       |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.71         |\n",
      "|    ep_rew_mean          | 1.84         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 392          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076038735 |\n",
      "|    clip_fraction        | 0.0879       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.488        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    std                  | 0.556        |\n",
      "|    value_loss           | 2.05         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.79        |\n",
      "|    ep_rew_mean          | 1.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008980582 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.544       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.554       |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 10         |\n",
      "|    ep_rew_mean          | 1.93       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 391        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830468 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.63      |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.427      |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.00183   |\n",
      "|    std                  | 0.546      |\n",
      "|    value_loss           | 1.71       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.1     |\n",
      "|    ep_rew_mean     | 1.93     |\n",
      "| time/              |          |\n",
      "|    fps             | 453      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.1        |\n",
      "|    ep_rew_mean          | 1.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008828731 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.538       |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.4        |\n",
      "|    ep_rew_mean          | 2.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010622419 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.72        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.533       |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.42        |\n",
      "|    ep_rew_mean          | 1.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014011746 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.566       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    std                  | 0.529       |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.1        |\n",
      "|    ep_rew_mean          | 2.08        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537335 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 2.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.5        |\n",
      "|    ep_rew_mean          | 1.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012467833 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 10.1         |\n",
      "|    ep_rew_mean          | 1.83         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086678285 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.544        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.518        |\n",
      "|    value_loss           | 1.71         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.1        |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015304816 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.793       |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.67       |\n",
      "|    ep_rew_mean          | 2.05       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 394        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01515798 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.813      |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.00696   |\n",
      "|    std                  | 0.515      |\n",
      "|    value_loss           | 1.77       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.84        |\n",
      "|    ep_rew_mean          | 1.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010232788 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.754       |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 0.518       |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.2     |\n",
      "|    ep_rew_mean     | 2        |\n",
      "| time/              |          |\n",
      "|    fps             | 482      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.68       |\n",
      "|    ep_rew_mean          | 1.87       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 438        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 9          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00975527 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.23       |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.00293   |\n",
      "|    std                  | 0.519      |\n",
      "|    value_loss           | 0.909      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.27        |\n",
      "|    ep_rew_mean          | 1.79        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 425         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008198461 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.819       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.516       |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.28        |\n",
      "|    ep_rew_mean          | 1.98        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015520734 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.283       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.516       |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.48        |\n",
      "|    ep_rew_mean          | 1.76        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021011725 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.768       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 0.514       |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.4        |\n",
      "|    ep_rew_mean          | 2.13        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010814115 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.625       |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.515       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.18        |\n",
      "|    ep_rew_mean          | 1.83        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011338573 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.000799   |\n",
      "|    std                  | 0.514       |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.6         |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014564229 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.496       |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.000182   |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.39        |\n",
      "|    ep_rew_mean          | 1.89        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021230085 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.535       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | 0.001       |\n",
      "|    std                  | 0.509       |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.98        |\n",
      "|    ep_rew_mean          | 2.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010686755 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    std                  | 0.506       |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.87     |\n",
      "|    ep_rew_mean     | 2.01     |\n",
      "| time/              |          |\n",
      "|    fps             | 176      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.7          |\n",
      "|    ep_rew_mean          | 2.08         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 169          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077810176 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.561        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | 0.000686     |\n",
      "|    std                  | 0.497        |\n",
      "|    value_loss           | 1.64         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.88        |\n",
      "|    ep_rew_mean          | 2.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013897178 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.593       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# model = PPO.load('P',env)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# render_freq = 1000  # 1000ステップごとにレンダリング\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# callback = CustomCallback(render_freq)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#progress_bar = True, callback=callback)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# # モデルのテスト\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# state, _ = env.reset()  # ここを修正\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# for i in trange(100):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m#         state, _ = env.reset() # エピソードが終了したら、環境をリセット\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# モデルの保存 (1)\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124modom_rl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:194\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 194\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 192\u001b[0m, in \u001b[0;36mMouseEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    187\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, reward, \u001b[38;5;28;01mFalse\u001b[39;00m, truncated, info\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:411\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmujoco_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera_name\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_rendering.py:673\u001b[0m, in \u001b[0;36mMujocoRenderer.render\u001b[1;34m(self, render_mode, camera_id, camera_name)\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m render_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mviewer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_rendering.py:413\u001b[0m, in \u001b[0;36mWindowViewer.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 413\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# clear overlay\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_rendering.py:365\u001b[0m, in \u001b[0;36mWindowViewer.render.<locals>.update\u001b[1;34m()\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewport\u001b[38;5;241m.\u001b[39mwidth, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewport\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m glfw\u001b[38;5;241m.\u001b[39mget_framebuffer_size(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow\n\u001b[0;32m    363\u001b[0m )\n\u001b[0;32m    364\u001b[0m \u001b[38;5;66;03m# update scene\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjv_updateScene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMjvPerturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjtCatBit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjCAT_ALL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# marker items\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m marker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markers:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC, PPO\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import datetime\n",
    "\n",
    "# env = gym.make(\"ALE/Breakout-v5\",  render_mode=\"human\")\n",
    "# env = gym.make(\"CartPole-v1\",  render_mode=\"human\")\n",
    "# # env = Monitor(env, \"./gym-results\", force=True, video_callable=lambda episode: True)　こんな感じで，\n",
    "# model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=200)\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "env = gym.make(\"MouseEnv-v0\", render_mode=\"human\")\n",
    "# video_path = \"./\"  # 保存先のpath\n",
    "# env = RecordVideo(env, video_path, video_length=500)\n",
    "env.model.opt.timestep = 0.01  # タイムステップを設定 RecordVideoする場合はそれ以降に書かないとerrorが出る\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "# model = PPO.load('P',env)\n",
    "# render_freq = 1000  # 1000ステップごとにレンダリング\n",
    "# callback = CustomCallback(render_freq)\n",
    "for i in range(300):\n",
    "    model.learn(total_timesteps=20000,)#progress_bar = True, callback=callback)\n",
    "\n",
    "\n",
    "\n",
    "    # # モデルのテスト\n",
    "    # state, _ = env.reset()  # ここを修正\n",
    "    # for unk in trange(100):\n",
    "    #     # 環境の描画\n",
    "    #     env.render()\n",
    "\n",
    "    #     # モデルの推論\n",
    "    #     action, _ = model.predict(state)\n",
    "\n",
    "    #     # 1ステップ実行\n",
    "    #     obs, reward, terminated, truncated, info = env.step(action) #以前の4要素のタプルから5要素のタプルに変更され，`observation, reward, terminated, truncated, info`という形式になった。\n",
    "\n",
    "\n",
    "\n",
    "    #     # エピソード完了（終了または切り捨て）のチェック terminated(終了した)は目的を達成してエピソードを終了したことを表す，truncated(切り捨てられた)は，達成できずにエピソードが終了したことを表す\n",
    "    #     if terminated or truncated:\n",
    "    #         state, _ = env.reset() # エピソードが終了したら、環境をリセット\n",
    "    # モデルの保存 (1)\n",
    "    model.save('odom_rl')\n",
    "    end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    total_time = end_time - start_time\n",
    "    bot = LINENotifyBot(access_token='UuzEJNM69oW7g0suO2FsWygFKvSK4vj7HnEBFLyi0mc')\n",
    "    bot.send(\n",
    "    message=\"今\"+str(i+1)+\"回目の学習が終了しました\\nかかった時間：\"+str(total_time)+\"秒かかりました\",\n",
    "    #image='picf' + str(i) + '.png',  # png or jpg\n",
    "    # sticker_package_id=1,\n",
    "    # sticker_id=6,\n",
    "    )\n",
    "\n",
    "# print(video_path)\n",
    "plt.title(\"1マス前進\", fontname=\"MS Gothic\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"step(s)\", fontname=\"MS Gothic\")\n",
    "plt.ylabel(\"速度[m/s]\", fontname=\"MS Gothic\")\n",
    "\n",
    "#前進関係のプロット\n",
    "t = list(range(len(env.reward_graph)))  # 0から始まるインデックスのリストを作成\n",
    "# plt.plot(env.mouse_ypos_graph, env.mouse_xpos_graph, linestyle='solid', label=\"報酬\")\n",
    "plt.legend()\n",
    "# 環境のクローズ\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mオドメトリ\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMS Gothic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid()\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx座標[m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMS Gothic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.title(\"オドメトリ\", fontname=\"MS Gothic\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"x座標[m]\", fontname=\"MS Gothic\")\n",
    "plt.ylabel(\"y座標[m]\", fontname=\"MS Gothic\")\n",
    "plt.plot(env.mouse_ypos_graph, env.mouse_xpos_graph, linestyle='solid', label=\"報酬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment `MouseEnv` doesn't exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseCallback\n\u001b[0;32m     10\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mreplace(microsecond\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMouseEnv-v0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m env\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mtimestep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# タイムステップを設定 RecordVideoする場合はそれ以降に書かないとerrorが出る\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# model = PPO(\"MlpPolicy\", env, verbose=1)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:767\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     env_spec \u001b[38;5;241m=\u001b[39m \u001b[43m_find_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env_spec, EnvSpec)\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# Update the env spec kwargs with the `make` kwargs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:529\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(env_id)\u001b[0m\n\u001b[0;32m    523\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the latest versioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_env_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead of the unversioned environment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m     )\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 529\u001b[0m     \u001b[43m_check_version_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo registered env with id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Did you register it, or import the package that registers it? Use `gymnasium.pprint_registry()` to see all of the registered environments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m env_spec\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:395\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[1;34m(ns, name, version)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_env_id(ns, name, version) \u001b[38;5;129;01min\u001b[39;00m registry:\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m \u001b[43m_check_name_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\gymenv\\Lib\\site-packages\\gymnasium\\envs\\registration.py:372\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[1;34m(ns, name)\u001b[0m\n\u001b[0;32m    369\u001b[0m namespace_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in namespace \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m suggestion_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Did you mean: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suggestion \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mNameNotFound(\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggestion_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m )\n",
      "\u001b[1;31mNameNotFound\u001b[0m: Environment `MouseEnv` doesn't exist."
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC, PPO\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "import datetime\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "env = gym.make(\"MouseEnv-v0\", render_mode=\"human\")\n",
    "env.model.opt.timestep = 0.01  # タイムステップを設定 RecordVideoする場合はそれ以降に書かないとerrorが出る\n",
    "\n",
    "# model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model = PPO.load('PPO',env)\n",
    "for i in range(3):\n",
    "    # モデルのテスト\n",
    "    state, _ = env.reset()  # ここを修正\n",
    "    for i in trange(100):\n",
    "        # 環境の描画\n",
    "        env.render()\n",
    "\n",
    "        # モデルの推論\n",
    "        action, _ = model.predict(state)\n",
    "\n",
    "        # 1ステップ実行\n",
    "        obs, reward, terminated, truncated, info = env.step(action) #以前の4要素のタプルから5要素のタプルに変更され，`observation, reward, terminated, truncated, info`という形式になった。\n",
    "        # エピソード完了（終了または切り捨て）のチェック terminated(終了した)は目的を達成してエピソードを終了したことを表す，truncated(切り捨てられた)は，達成できずにエピソードが終了したことを表す\n",
    "        if terminated or truncated:\n",
    "            state, _ = env.reset() # エピソードが終了したら、環境をリセット\n",
    "# 環境のクローズ\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "{'render_modes': ['human', 'rgb_array'], 'render_fps': 50}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "env = gym.make('CartPole-v1')\n",
    "print(env.metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## env.step(action)の戻り値の更新について（４つから５つになりました）\n",
    "Gymライブラリのバージョン0.26以降、及びGymnasiumの全バージョンにおいて、`env.step()`メソッドの戻り値は、以前の4要素のタプルから5要素のタプルに変更されました。これまでの`observation, reward, done, info`という形式から、`observation, reward, terminated, truncated, info`という形式になっています。\n",
    "\n",
    "ここでの`terminated`と`truncated`はどちらもブール値（真偽値）です。`terminated`は環境がマルコフ決定過程（MDP）のタスクの定義に基づいて終了状態に達したことを示します。これは通常、環境の目標が達成されたり、終了条件が満たされたときに発生します。一方、`truncated`は、エピソードがMDPの範囲外の条件、たとえば時間制限や境界条件（エージェントが境界を越えるなど）によって終了したことを示します。強化学習アルゴリズムにおいて、特にブートストラップを伴うものでは、終了と切り捨て状態の取り扱いが値の更新において異なる場合があるため、この区別は重要です。\n",
    "\n",
    "Gymライブラリのこの更新は、強化学習タスクにおける終了と切り捨ての明確な区別を提供するために行われました。これは、特定のアルゴリズムの正確な実装にとって重要です。終了(`terminated`)と切り捨て(`truncated`)の両方のタイプのエピソード終了を区別するために、両方が含まれるようになりました。\n",
    "\n",
    "あなたの目的に合わせて、エピソードが終了したかどうか（理由に関係なく）を知りたい場合は、`terminated`または`truncated`のいずれかが`True`であるかどうかを確認すればよいです。その場合、環境をリセットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのテスト\n",
    "state, _ = env.reset()  # ここを修正\n",
    "for i in trange(4000):\n",
    "    # 環境の描画\n",
    "    env.render()\n",
    "\n",
    "    # モデルの推論\n",
    "    action, _ = model.predict(state)\n",
    "\n",
    "    # 1ステップ実行\n",
    "    state, rewards, done, info = env.step(action)\n",
    "\n",
    "    # エピソード完了\n",
    "    if done:\n",
    "        state, _ = env.reset()  # エピソードが終了したら、環境をリセット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_string_example():\n",
    "        \"\"\"ドックストリング（Docstring）\n",
    "        この関数は以下のことを行います：\\n\n",
    "    - param1を処理します。\\n\n",
    "    - param2を別の方法で処理します。\\n\n",
    "    最後に、結果を返します。\n",
    "        シミュレーションをnフレーム進め、制御アクションを適用する。\n",
    "        Step the simulation n number of frames and applying a control action.\n",
    "        \"\"\"\n",
    "        p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordVideo\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
